{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_nltk.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Yadukrishnan1/NLP/blob/main/NLTK/summarization_nltk.ipynb",
      "authorship_tag": "ABX9TyMO8cB8tLI6aiTzdYHRqzdV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yadukrishnan1/NLP/blob/main/NLTK/summarization_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='/content/drive/MyDrive/Colab_Notebooks/NLP/Summarization'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ESXn6xgrqcGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e7ceaf-2530-41a4-a38b-131fdbb81409"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6qeXsNanqQ8t"
      },
      "outputs": [],
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxhUImV30Fl8",
        "outputId": "82cd954f-cd8b-4034-a341-04bbfacb7ff2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras-attention\n",
        "! pip install feedparser"
      ],
      "metadata": {
        "id": "fgQh9-zBye-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6afff81-9d05-42e4-e49b-48069e35f7ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-attention in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-attention) (2.8.0)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (6.0.8)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/Colab_Notebooks/NLP/Summarization/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbNAvTPGu26Z",
        "outputId": "d70da5a9-376b-4817-d77a-d448cf26eebc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention.py\t\t  text-summarization-with-seq2seq-model.ipynb\n",
            "summarization_nltk.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "python_arXiv_parsing\n",
        "\n",
        "Please see the documentation at \n",
        "http://export.arxiv.org/api_help/docs/user-manual.html\n",
        "\"\"\"\n",
        "\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import feedparser\n",
        "\n",
        "# Base api query url\n",
        "base_url = 'http://export.arxiv.org/api/query?';\n",
        "\n",
        "# Search parameters\n",
        "search_query = 'all:economics' # search for electron in all fields\n",
        "start = 0                     # retreive the first 5 results\n",
        "max_results = 1000\n",
        "\n",
        "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
        "                                                     start,\n",
        "                                                     max_results)\n",
        "\n",
        "# Opensearch metadata such as totalResults, startIndex, \n",
        "# and itemsPerPage live in the opensearch namespase.\n",
        "# Some entry metadata lives in the arXiv namespace.\n",
        "# This is a hack to expose both of these namespaces in\n",
        "# feedparser v4.1\n",
        "\n",
        "# feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
        "# feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
        "\n",
        "# perform a GET request using the base_url and query\n",
        "response = urllib.request.urlopen(base_url+query).read()\n",
        "\n",
        "# parse the response using feedparser\n",
        "feed = feedparser.parse(response)\n",
        "\n",
        "# print out feed information\n",
        "# print ('Feed title: {}'.format(feed.feed.title))\n",
        "# print ('Feed last updated: {}'.format(feed.feed.updated))\n",
        "\n",
        "# print opensearch metadata\n",
        "# print ('totalResults for this query: {}'.format(feed.feed.opensearch_totalresults))\n",
        "# print ('itemsPerPage for this query: {}'.format(feed.feed.opensearch_itemsperpage))\n",
        "# print ('startIndex for this query: {}'  .format(feed.feed.opensearch_startindex))\n",
        "\n",
        "# Run through each entry, and print out information\n",
        "title_list=[]\n",
        "abstract_list=[]\n",
        "for entry in feed.entries:\n",
        "    title_list.append(entry.title)\n",
        "    \n",
        "    # The abstract is in the <summary> element\n",
        "    abstract_list.append(entry.summary)\n",
        "\n",
        "data = pd.DataFrame(list(zip(title_list, abstract_list)), columns=['title','abstract'])\n"
      ],
      "metadata": {
        "id": "74gIWtNruYpr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(subset=['abstract', 'title'],inplace=True)  #dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)   #dropping na"
      ],
      "metadata": {
        "id": "uId5linHy5LJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Z-_F1WOq2uBZ",
        "outputId": "bb492726-6c25-402f-87a2-cf9564f4cd21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                  title  \\\n",
              "0                                                                                                      The Link Between Standardization and Economic Growth: A Bibliometric\\n  Analysis   \n",
              "1                                                                                                                                       Business Cycles as Collective Risk Fluctuations   \n",
              "2                                                                                                                      Econophysics of Macroeconomics: \"Action-at-a-Distance\" and Waves   \n",
              "3                                                                                                                                                      Econophysics Macroeconomic Model   \n",
              "4  Economic prospects of the Russian-Chinese partnership in the logistics\\n  projects of the Eurasian Economic Union and the Silk Road Economic Belt: a\\n  scientific literature review   \n",
              "\n",
              "                                                                                                                                                                                                  abstract  \n",
              "0  We analyze the link between standardization and economic growth by\\nsystematically reviewing leading economics journals, leading economic growth\\nresearchers' articles, and economic growth-related...  \n",
              "1  We suggest use continuous numerical risk grades [0,1] of R for a single risk\\nor the unit cube in Rn for n risks as the economic domain. We consider risk\\nratings of economic agents as their coord...  \n",
              "2  We present macroeconomic model that describes evolution of macroeconomic\\nvariables and macroeconomic waves on economic space. Risk ratings of economic\\nagents play role of their coordinates on ec...  \n",
              "3  This paper presents macroeconomic model that is based on parallels between\\nmacroeconomic multi-agent systems and multi-particle systems. We use risk\\nratings of economic agents as their coordinat...  \n",
              "4  The authors of the article have reviewed the scientific literature on the\\ndevelopment of the Russian-Chinese cooperation in the field of combining\\neconomic and logistics projects of the Eurasian...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-331d34bf-b313-4368-bf29-18ab434cc60e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Link Between Standardization and Economic Growth: A Bibliometric\\n  Analysis</td>\n",
              "      <td>We analyze the link between standardization and economic growth by\\nsystematically reviewing leading economics journals, leading economic growth\\nresearchers' articles, and economic growth-related...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business Cycles as Collective Risk Fluctuations</td>\n",
              "      <td>We suggest use continuous numerical risk grades [0,1] of R for a single risk\\nor the unit cube in Rn for n risks as the economic domain. We consider risk\\nratings of economic agents as their coord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Econophysics of Macroeconomics: \"Action-at-a-Distance\" and Waves</td>\n",
              "      <td>We present macroeconomic model that describes evolution of macroeconomic\\nvariables and macroeconomic waves on economic space. Risk ratings of economic\\nagents play role of their coordinates on ec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Econophysics Macroeconomic Model</td>\n",
              "      <td>This paper presents macroeconomic model that is based on parallels between\\nmacroeconomic multi-agent systems and multi-particle systems. We use risk\\nratings of economic agents as their coordinat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Economic prospects of the Russian-Chinese partnership in the logistics\\n  projects of the Eurasian Economic Union and the Silk Road Economic Belt: a\\n  scientific literature review</td>\n",
              "      <td>The authors of the article have reviewed the scientific literature on the\\ndevelopment of the Russian-Chinese cooperation in the field of combining\\neconomic and logistics projects of the Eurasian...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-331d34bf-b313-4368-bf29-18ab434cc60e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-331d34bf-b313-4368-bf29-18ab434cc60e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-331d34bf-b313-4368-bf29-18ab434cc60e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "RiIQx-gPzI8w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning of the Abstracts (long texts)"
      ],
      "metadata": {
        "id": "GRjt9KuS1muH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def abstract_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_abstract = []\n",
        "for t in data['abstract']:\n",
        "    cleaned_abstract.append(abstract_cleaner(t))"
      ],
      "metadata": {
        "id": "PlT58Vq3z6fw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def title_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_title = []\n",
        "for t in data['title']:\n",
        "    cleaned_title.append(title_cleaner(t))\n"
      ],
      "metadata": {
        "id": "VuRk5Bry107F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_abstract']=cleaned_abstract\n",
        "data['cleaned_title']=cleaned_title\n",
        "data['cleaned_title'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "fA-u17vz2AhF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DfNoWNb_2Ktp",
        "outputId": "34d6292a-8e54-4ecf-8cc6-ff483bdeeb66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                  title  \\\n",
              "0                                                                                                      The Link Between Standardization and Economic Growth: A Bibliometric\\n  Analysis   \n",
              "1                                                                                                                                       Business Cycles as Collective Risk Fluctuations   \n",
              "2                                                                                                                      Econophysics of Macroeconomics: \"Action-at-a-Distance\" and Waves   \n",
              "3                                                                                                                                                      Econophysics Macroeconomic Model   \n",
              "4  Economic prospects of the Russian-Chinese partnership in the logistics\\n  projects of the Eurasian Economic Union and the Silk Road Economic Belt: a\\n  scientific literature review   \n",
              "\n",
              "                                                                                                                                                                                                  abstract  \\\n",
              "0  We analyze the link between standardization and economic growth by\\nsystematically reviewing leading economics journals, leading economic growth\\nresearchers' articles, and economic growth-related...   \n",
              "1  We suggest use continuous numerical risk grades [0,1] of R for a single risk\\nor the unit cube in Rn for n risks as the economic domain. We consider risk\\nratings of economic agents as their coord...   \n",
              "2  We present macroeconomic model that describes evolution of macroeconomic\\nvariables and macroeconomic waves on economic space. Risk ratings of economic\\nagents play role of their coordinates on ec...   \n",
              "3  This paper presents macroeconomic model that is based on parallels between\\nmacroeconomic multi-agent systems and multi-particle systems. We use risk\\nratings of economic agents as their coordinat...   \n",
              "4  The authors of the article have reviewed the scientific literature on the\\ndevelopment of the Russian-Chinese cooperation in the field of combining\\neconomic and logistics projects of the Eurasian...   \n",
              "\n",
              "                                                                                                                                                                                          cleaned_abstract  \\\n",
              "0  analyze link standardization economic growth systematically reviewing leading economics journals leading economic growth researchers articles economic growth related books make following observati...   \n",
              "1  suggest use continuous numerical risk grades single risk unit cube risks economic domain consider risk ratings economic agents coordinates economic domain economic activity agents economic factors...   \n",
              "2  present macroeconomic model describes evolution macroeconomic variables macroeconomic waves economic space risk ratings economic agents play role coordinates economic space aggregation economic va...   \n",
              "3  paper presents macroeconomic model based parallels macroeconomic multi agent systems multi particle systems use risk ratings economic agents coordinates economic space aggregates economic financia...   \n",
              "4  authors article reviewed scientific literature development russian chinese cooperation field combining economic logistics projects eurasian economic union silk road economic belt opinions russian ...   \n",
              "\n",
              "                                                                                                                                                                  cleaned_title  \n",
              "0                                                                                                   the link between standardization and economic growth bibliometric analysis   \n",
              "1                                                                                                                              business cycles as collective risk fluctuations   \n",
              "2                                                                                                                  econophysics of macroeconomics action at distance and waves   \n",
              "3                                                                                                                                             econophysics macroeconomic model   \n",
              "4  economic prospects of the russian chinese partnership in the logistics projects of the eurasian economic union and the silk road economic belt scientific literature review   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d4762e3-e463-47a1-9a95-0d84b85abf83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>cleaned_abstract</th>\n",
              "      <th>cleaned_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Link Between Standardization and Economic Growth: A Bibliometric\\n  Analysis</td>\n",
              "      <td>We analyze the link between standardization and economic growth by\\nsystematically reviewing leading economics journals, leading economic growth\\nresearchers' articles, and economic growth-related...</td>\n",
              "      <td>analyze link standardization economic growth systematically reviewing leading economics journals leading economic growth researchers articles economic growth related books make following observati...</td>\n",
              "      <td>the link between standardization and economic growth bibliometric analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business Cycles as Collective Risk Fluctuations</td>\n",
              "      <td>We suggest use continuous numerical risk grades [0,1] of R for a single risk\\nor the unit cube in Rn for n risks as the economic domain. We consider risk\\nratings of economic agents as their coord...</td>\n",
              "      <td>suggest use continuous numerical risk grades single risk unit cube risks economic domain consider risk ratings economic agents coordinates economic domain economic activity agents economic factors...</td>\n",
              "      <td>business cycles as collective risk fluctuations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Econophysics of Macroeconomics: \"Action-at-a-Distance\" and Waves</td>\n",
              "      <td>We present macroeconomic model that describes evolution of macroeconomic\\nvariables and macroeconomic waves on economic space. Risk ratings of economic\\nagents play role of their coordinates on ec...</td>\n",
              "      <td>present macroeconomic model describes evolution macroeconomic variables macroeconomic waves economic space risk ratings economic agents play role coordinates economic space aggregation economic va...</td>\n",
              "      <td>econophysics of macroeconomics action at distance and waves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Econophysics Macroeconomic Model</td>\n",
              "      <td>This paper presents macroeconomic model that is based on parallels between\\nmacroeconomic multi-agent systems and multi-particle systems. We use risk\\nratings of economic agents as their coordinat...</td>\n",
              "      <td>paper presents macroeconomic model based parallels macroeconomic multi agent systems multi particle systems use risk ratings economic agents coordinates economic space aggregates economic financia...</td>\n",
              "      <td>econophysics macroeconomic model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Economic prospects of the Russian-Chinese partnership in the logistics\\n  projects of the Eurasian Economic Union and the Silk Road Economic Belt: a\\n  scientific literature review</td>\n",
              "      <td>The authors of the article have reviewed the scientific literature on the\\ndevelopment of the Russian-Chinese cooperation in the field of combining\\neconomic and logistics projects of the Eurasian...</td>\n",
              "      <td>authors article reviewed scientific literature development russian chinese cooperation field combining economic logistics projects eurasian economic union silk road economic belt opinions russian ...</td>\n",
              "      <td>economic prospects of the russian chinese partnership in the logistics projects of the eurasian economic union and the silk road economic belt scientific literature review</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d4762e3-e463-47a1-9a95-0d84b85abf83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d4762e3-e463-47a1-9a95-0d84b85abf83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d4762e3-e463-47a1-9a95-0d84b85abf83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_title'] = data['cleaned_title'].apply(lambda x : '_START_ '+ x + ' _END_')"
      ],
      "metadata": {
        "id": "-cqkIaOP2RbO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(\"Abstract:\",data['cleaned_abstract'][i])\n",
        "    print(\"Title:\",data['cleaned_title'][i])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM-Lh_7E3Hv4",
        "outputId": "021cbef1-6386-41b4-e32f-078010b161ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract: analyze link standardization economic growth systematically reviewing leading economics journals leading economic growth researchers articles economic growth related books make following observations article analyzed link standardization economic growth top economics journals representative sample leading researchers economic growth allocated little attention link standardization economic growth typically economic growth textbooks contain standards standardization word indexes findings suggest economic growth theory neglected role standardization\n",
            "Title: _START_ the link between standardization and economic growth bibliometric analysis  _END_\n",
            "\n",
            "\n",
            "Abstract: suggest use continuous numerical risk grades single risk unit cube risks economic domain consider risk ratings economic agents coordinates economic domain economic activity agents economic factors change agents risk ratings cause motion agents economic domain aggregations variables transactions individual agents small volume economic domain establish continuous economic media approximation describes collective variables transactions flows economic domain functions risk coordinates economic variable defines mean risk risk weighted economic variable collective flows economic variables bounded economic domain fluctuate secure risky area back fluctuations flows cause time oscillations macroeconomic variables mean risks economic domain origin business credit cycles derive equations describe evolution collective variables transactions flows economic domain illustration present simple self consistent equations supply demand cycles describe fluctuations supply demand mean risks\n",
            "Title: _START_ business cycles as collective risk fluctuations  _END_\n",
            "\n",
            "\n",
            "Abstract: present macroeconomic model describes evolution macroeconomic variables macroeconomic waves economic space risk ratings economic agents play role coordinates economic space aggregation economic variables like assets investment credits loans economic agents point define corresponding macroeconomic variables functions time coordinates economic space evolution macroeconomic variables determined economic financial transactions economic agents transactions occur economic agents coordinates reflect non local action distance character internal macroeconomic interactions instance buy sell transactions points economic space define dynamics assets point investment point aggregates transactions economic agents point economic space define economic fields functions two coordinates describe dynamics economic fields economic space derive hydrodynamic like equations simple models interactions economic fields derive hydrodynamic like equations closed form obtain wave equations perturbations economic field waves propagate economic space amplitudes grow exponent time may disturb economic stability diversities macroeconomic financial waves economic space simple models uncover importance wave processes macroeconomic modeling forecasting\n",
            "Title: _START_ econophysics of macroeconomics action at distance and waves  _END_\n",
            "\n",
            "\n",
            "Abstract: paper presents macroeconomic model based parallels macroeconomic multi agent systems multi particle systems use risk ratings economic agents coordinates economic space aggregates economic financial variables like investment assets demand credits etc economic agents near point define corresponding macroeconomic variables functions time coordinates economic space parallels multi agent multi particle systems economic space allow describe transition economic kinetic like economic hydrodynamic like approximation derive macroeconomic hydrodynamic like equations economic space economic financial transactions economic agents determine evolution macroeconomic variables paper describes local macroeconomic approximation takes account transactions economic agents coordinates near point economic space describes interaction macroeconomic variables linear differential operators simple model interaction macroeconomic variables demand investment interest rate derive hydrodynamic like equations closed form perturbations macroeconomic variables derive macroeconomic wave equations macroeconomic waves economic space propagate exponential growth amplitude cause irregular time fluctuations macroeconomic variables induce economic crises\n",
            "Title: _START_ econophysics macroeconomic model  _END_\n",
            "\n",
            "\n",
            "Abstract: authors article reviewed scientific literature development russian chinese cooperation field combining economic logistics projects eurasian economic union silk road economic belt opinions russian also chinese experts projects indicated provides expansion vision concept new silk road countries\n",
            "Title: _START_ economic prospects of the russian chinese partnership in the logistics projects of the eurasian economic union and the silk road economic belt scientific literature review  _END_\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_abstract']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_title']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'abstract':text_word_count, 'title':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hpPcWY053Qs-",
        "outputId": "36819f43-f0f0-4286-a4e4-e576ce380edd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_abstract=250 \n",
        "max_len_title=40"
      ],
      "metadata": {
        "id": "mC-3-LYJ3c6C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(data['cleaned_abstract'],data['cleaned_title'],test_size=0.1,random_state=0,shuffle=True)\n"
      ],
      "metadata": {
        "id": "BvEi7ANl3s3C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_tr shape - ', x_tr.shape)\n",
        "print('y_tr shape - ', y_tr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loogRwaBX8M0",
        "outputId": "1d384d11-0dca-431f-fc00-e1cf3523dc99"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_tr shape -  (900,)\n",
            "y_tr shape -  (900,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3gNUfNTYHnB",
        "outputId": "3cd1c97a-e582-4f91-8d1d-ace8118fe47c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "785    research highlighted relationships size scaled growth across large variety biological social organisms ranging bacteria animals plants cities companies yet heretofore identifying similar relations...\n",
              "873    paper examines deposits individuals large companies banking industry deposit types impacted macroeconomic factors quantitative easing actual data deposits holder unavailable use dataset banks fina...\n",
              "65     regulation commonly viewed hindrance entrepreneurship heterogeneity effects regulation rarely explored focus regional variation effects national level regulations developing theory hierarchical in...\n",
              "902    economic model predictive control recently gained popularity due ability directly optimize given performance criterion enforcing constraint satisfaction nonlinear systems recent research developed...\n",
              "317    large acute economic shocks financial crisis current covid infections rapidly change economic environment situation importance real time economic analysis using alternative datais emerging alterna...\n",
              "Name: cleaned_abstract, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_tr.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TyK02wB_EhO",
        "outputId": "392045b5-f942-4cf5-f26c-29eb64b68f62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "785                                                       _START_ nighttime light superlinear growth and economic inequalities at the country level  _END_\n",
              "873                                                        _START_ where does the stimulus go deep generative model for commercial banking deposits  _END_\n",
              "65     _START_ the interdependence of hierarchical institutions federal regulation job creation and the moderating effect of state economic freedom  _END_\n",
              "902                                                         _START_ new dissipativity condition for asymptotic stability of discounted economic mpc  _END_\n",
              "317                                                                                             _START_ aggregate learning for mixed frequency data  _END_\n",
              "Name: cleaned_title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for abstracts on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_abstract, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_abstract, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ],
      "metadata": {
        "id": "Aut44bN03xrm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing a tokenizer for title on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_title, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_title, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "metadata": {
        "id": "2mi9EDfL36N5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_tr shape - ', x_tr.shape)\n",
        "print('y_tr shape - ', y_tr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5qfqujBYVmd",
        "outputId": "88799bc3-8d90-4530-8eff-b261e4a37e67"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_tr shape -  (900, 250)\n",
            "y_tr shape -  (900, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K \n",
        "import gensim\n",
        "from numpy import *\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_len_abstract,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc_size, embedding_dim, trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc_size, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-feUzyLn9bEF",
        "outputId": "505d6b33-f6aa-49fe-9931-2b12afba1844"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 250, 200)     1757000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 250, 300),   601200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 250, 300),   721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    486600      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 250, 300),   721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 2433)  732333      ['lstm_3[0][0]']                 \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,620,733\n",
            "Trainable params: 5,620,733\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "iCu-DeSG4ZM6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
      ],
      "metadata": {
        "id": "gOcA2vq--QTq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_tr[:,:-1].shape)\n",
        "print(x_tr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys-aAwVzVutz",
        "outputId": "fdc14833-93f9-4e71-f76f-c34a5e2c41f1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 39)\n",
            "(900, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([x_tr, y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4g0EnTa-T9g",
        "outputId": "7d00711a-afb4-43d1-c125-935003792c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dDcZVc0-wpd"
      },
      "source": [
        "**Visualize the model learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad3oAgPH-wpd"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FS2kuwD-wpd"
      },
      "source": [
        "**Next, lets build the dictionary to convert the index to word for target and source vocabulary:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfiGEMqN-wpd"
      },
      "outputs": [],
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SROJSqAr-wpe"
      },
      "outputs": [],
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_abstract, latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFA9s3xm-wpe"
      },
      "source": [
        "**We are defining a function below which is the implementation of the inference process**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QEtXP1C-wpe"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='start'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end'  or len(decoded_sentence.split()) >= (max_len_title-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_sequence(x_tr[1].reshape(1, max_len_abstract))"
      ],
      "metadata": {
        "id": "FFzmRBLyG-VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odl1QDm1-wpe"
      },
      "source": [
        "**Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsdJabk8-wpe"
      },
      "outputs": [],
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQE0fUPg-wpf"
      },
      "source": [
        "**Run the model over the data to see the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs8BzNtx-wpf"
      },
      "outputs": [],
      "source": [
        "for i in range(2,5):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_len_abstract)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3K_sbgMYG5_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}